# TokenLearner:What Can 8 Learned Tokens Do for Images and Videos?
## Abstract:
1. A new visure representation learning using a small number of adaptively learned tokens, can be used to image/video understanding tasks.
2. Code: https://github.com/google-research/scenic/tree/main/scenic/projects/token_learner

## Introduction:
1. image understanding task + identifying most important input both spaticially and temporally = video undertanding task
2. The Vison Transformer (VIT) treats images as a sequence of patches, utilizing the Transformer architecture similar to text understanding.
3. Tranditional methods are computationally heavy.
4. The main question addressed in this work is how to adaptively learn the representation from visualinputs to most effectively capture the spatial information for images and spatio-temporal interactions for videos.
5. Key points:
* represent visual data by learning to ‘tokenize’ the input
* learn to compute important regions in the video/image -adaptively learn
* using a small amount of tokens without decreasing the performance





## Good expressions:
1. a handful of = a very small number of people or things
2. departing from
3. The first key observation is ...
4. This approach is simple, efficient, and as shown by results, outperforms methods including both... and ... from prior arts.
5. performs comparably 性能相当
6. contemporary work
